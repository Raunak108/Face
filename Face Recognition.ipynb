{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\" float:right; display:inline\" src=\"http://opencloud.utsa.edu/wp-content/themes/utsa-oci/images/logo.png\"/>\n",
    "\n",
    "### **University of Texas at San Antonio** \n",
    "\n",
    "## [<font color=\"000\"; size=\"7pt\" >**Open Cloud Institute** </font>](http://opencloud.utsa.edu) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Machine Learning/BigData EE-6973-001-Fall-2016\n",
    "\n",
    "\n",
    "## **Paul Rad, Ph.D.**  \n",
    "## **Ali Miraftab, Research Fellow - Ph.D. Candidate**\n",
    "\n",
    "  \n",
    "\n",
    "<hr style=\"height:1.5px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:1.5px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center; font-family:Bebas Neue; font-size:380%;\"> <font color=\"000\"> **Face Recognition Using a Hybrid ResNet-ConvNet Neural Network** </font> </h1>\n",
    "\n",
    "<br/><br/>\n",
    "<center><h1 style=\"text-align:center; font-family:Bebas Neue; font-size:180%;\"> *Ali Miraftab, Paul Rad* </h1><center>\n",
    "\n",
    "\n",
    "    \n",
    "<br/>\n",
    "<center> <span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.6em;\"> *Open Cloud Institute, University of Texas at San Antonio, San Antonio, Texas, USA* </span> <center>\n",
    "\n",
    "<br/>\n",
    "<center> <span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.6em;\"> {Ali.Miraftab, Paul.Rad}@utsa.edu </span> <center>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Dataset:** </span> <font size = \"4.5\" face=\"Bebas Neue\" color=\"black\"> The image data can be found in [http://www.cs.cmu.edu/afs/][1]. This directory contains 20 subdirectories, one for each person, named by userid.  Each of these directories contains several different face images of the same person. </font>\n",
    "\n",
    "[1]: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-8/faceimages/faces/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Outcome:** </span> <font size = \"4.5\" face=\"Bebas Neue\" color=\"black\"> Applying resnet and convnet to identify the direction of the face </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Project Definition:** </span> <font size = \"4.5\" face=\"Bebas Neue\" color=\"black\"> Using deep neural network models, ResNet and Convnet, classification of camera images of faces of various people in various poses is sudied. The dataset includes images of 20 different people, approximately 32 images per person, varying the person's expression (happy, sad, angry, neutral), the direction in which they are looking (left, right, straight ahead, up), and whether or not they were wearing sunglassess.\n",
    "\n",
    "There is also variation in the background behind the person, the clothing worn by the person, and theposition of the person's face within the image. I total. 624 greyscale images were collected, each whithin a resolutoin of 120by128, with each image pixel described by a greyscale intensity value between 0 (black) and 255 (white).\n",
    "\n",
    "\n",
    "A variety of target function can be learn from this image data. For example, given an image as input we could train a model to output the identity of the person, the direction in which the person is facing, the gender of the person, whether or not they are wearning sunglasses, etc. All of this target functions can be learned to high accuracy from this image data. In this course research we consider the particular task: learning the direction in which the person is facing (to their left, right, straight ahead, or upward).  </font> [1]\n",
    "\n",
    "[1]: Mitchell, T. M. (1997). Machine Learning. New York: McGraw-Hill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"width:830; background-color:white; height:220px; overflow:scroll; overflow-x: scroll;overflow-y: hidden;\">\n",
    "\n",
    "<img style=\" float:left; display:inline\" src=\"\" width=\"160\" height=\"90\"/>\n",
    "\n",
    "<img style=\" float:left; display:inline\" src=\"https://archive.ics.uci.edu/ml/machine-learning-databases/faces-mld/at33_left_happy_sunglasses.jpg\" width=\"160\" height=\"90\"/>\n",
    "\n",
    "<img style=\" float:left; display:inline\" src=\"https://archive.ics.uci.edu/ml/machine-learning-databases/faces-mld/an2i_straight_neutral_open.jpg\" width=\"160\" height=\"90\"/>\n",
    "\n",
    "<img style=\" float:left; display:inline\" src=\"https://archive.ics.uci.edu/ml/machine-learning-databases/faces-mld/ch4f_up_angry_sunglasses.jpg\" width=\"160\" height=\"90\"/>\n",
    "\n",
    "<img style=\" float:left; display:inline\" src=\"https://archive.ics.uci.edu/ml/machine-learning-databases/faces-mld/boland_right_sad_open.jpg\" width=\"160\" height=\"90\"/>\n",
    "\n",
    "<img style=\" float:left; display:inline\" src=\"http://jmvidal.cse.sc.edu/talks/ann/mitchell-straight-happy-sunglasses-4.png\" width=\"160\" height=\"90\"/>\n",
    "\n",
    "\n",
    "<img style=\" float:left; display:inline\" src=\"http://jmvidal.cse.sc.edu/talks/ann/pose100-h2.png\" width=\"160\" height=\"90\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Design Choices:** </span> </span> <font size = \"4.5\" face=\"Bebas Neue\" color=\"black\"> to be explain </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Input Encoding:** </span> </span> <font size = \"4.5\" face=\"Bebas Neue\" color=\"black\"> to be explain </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Output Encoding:** </span> </span> <font size = \"4.5\" face=\"Bebas Neue\" color=\"black\"> to be explain </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Network Graph Structure:** </span> </span> <font size = \"4.5\" face=\"Bebas Neue\" color=\"black\"> to be explain </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Other Learning Algorithm Parameters:** </span> </span> <font size = \"4.5\" face=\"Bebas Neue\" color=\"black\"> to be explain </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
